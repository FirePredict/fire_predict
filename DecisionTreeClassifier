from sklearn.ensemble import AdaBoostClassifier
from sklearn import preprocessing
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import f1_score

import numpy as np
import pandas as pd
import seaborn as sns

import matplotlib.pyplot as plt
%matplotlib inline 

############################################ Lecture des fichiers ######################################
##################################### Préparation et analyse des données ###############################

mobilisation = pd.read_csv("LFB Mobilisation data Last 3 years.csv", header=0, sep=";");
incident = pd.read_csv("LFB Incident data Last 3 years.csv", header=0, sep=";");

total = pd.merge(incident, mobilisation, on='IncidentNumber')

total.drop(["IncidentGroup","PropertyCategory","Postcode_full","UPRN","USRN","IncGeo_BoroughCode","ProperCase",
           "IncGeo_WardCode","IncGeo_WardName","Easting_m","Northing_m","Easting_rounded","Northing_rounded",
           "Latitude","Longitude","FRS","IncidentStationGround","FirstPumpArriving_AttendanceTime",
           "FirstPumpArriving_DeployedFromStation","SecondPumpArriving_AttendanceTime",
           "SecondPumpArriving_DeployedFromStation","NumStationsWithPumpsAttending","NumPumpsAttending",
           "PumpCount","PumpHoursRoundUp","Notional Cost (£)","CalYear_y","HourOfCall_y","ResourceMobilisationId",
           "PerformanceReporting","DateAndTimeMobilised","DateAndTimeMobile","DateAndTimeArrived","TurnoutTimeSeconds",
           "TravelTimeSeconds","DateAndTimeLeft","DateAndTimeReturned","DeployedFromStation_Code","PumpOrder",
           "PlusCode_Code","PlusCode_Description","DelayCodeId","DelayCode_Description"], axis=1, inplace=True)
 
total['SpecialServiceType']=total['SpecialServiceType'].fillna(total['StopCodeDescription'])
total.drop(['StopCodeDescription'], axis=1, inplace=True)
total = total.dropna() 

total['DateOfCall'] = pd.to_datetime(total['DateOfCall'])
total['dayOfWeek'] = total['DateOfCall'].dt.dayofweek
total['month'] = total['DateOfCall'].dt.month

# Suppression de la colonne Numéro d'incident
# Cette information est purement indicatrice et 
# ne rentre pas en compte dans l'apprentissage du modèle
total = total.drop('IncidentNumber',axis=1)

# Transformation du type de la colonne Date de l'appel en type Object
# pour la compatibilité du modèle
total['DateOfCall'] = total['DateOfCall'].astype(object)

# Liste des colonnes catégorielles
objColumn = list(total.select_dtypes(include=['object']).columns)

# Transformation des variables catégorielles en variables indicatrices 
# pour la compatibilité avec le modèle d'apprentissage
enc = OrdinalEncoder()
enc.fit(total[objColumn])
total[objColumn] = enc.transform(total[objColumn])

# Centrer et réduire les variables numériques ????
#numColumn = list(total.select_dtypes(exclude=['object']).columns)
#total[numColumn] = pd.DataFrame(preprocessing.StandardScaler().fit_transform(total[numColumn]))

# Séparation de la variable cible du reste des autres variables
data = total.drop('AttendanceTimeSeconds', axis=1)
target = total.AttendanceTimeSeconds
 
# Séparation des données en un ensemble d'apprentissage et un ensemble de Test 
# avec 20% des données originales pour le Test
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123) 

# Création d'un modèle de classifieur basé sur un arbre de décision
# et entrainement du modèle
dtc = DecisionTreeClassifier(criterion ='entropy', max_depth=5, random_state=123)
dtc.fit(X_train, y_train)

# Affichage du score 
score_dtc = dtc.score(X_test, y_test)
print(score_dtc)

# On applique le modèle aux données de l'ensemble de test et on stocke les prédictions obtenues
# Affichage de la matrice de confusion pour comparer les classes réelles et prédites
y_pred = dtc.predict(X_test)
print(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))

# Affichage des variables les plus importantes qui ont influencé le modèle
dtc.feature_importances_
feats = {}
for feature, importance in zip(data.columns, dtc.feature_importances_):
    feats[feature] = importance 
    
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Entropy-importance'})
print(importances.sort_values(by='Entropy-importance', ascending=False).head(8))

# Création d'un modèle de classifieur basé sur un arbre de décision
# avec le criterion gini et une profondeur diminué à 4
# Avec entrainement du modèle et prédictions obtenues
dtc_gini = DecisionTreeClassifier(criterion ='gini', max_depth=4, random_state=321)
dtc_gini.fit(X_train, y_train)
y_pred = dtc_gini.predict(X_test)

# Affichage de la matrice de confusion pour comparer les classes réelles et prédites
print(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))

# Affichage des variables les plus importantes qui ont influencé le modèle
feats = {}
for feature, importance in zip(data.columns, dtc_gini.feature_importances_):
    feats[feature] = importance 
    
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})
print(importances.sort_values(by='Gini-importance', ascending=False).head(8))

plt.figure(figsize=(20, 15))
tree.plot_tree(dtc)
#tree.plot_tree(dtc_gini)
